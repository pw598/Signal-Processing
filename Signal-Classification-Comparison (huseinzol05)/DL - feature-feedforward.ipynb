{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display,Audio,HTML\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import speechpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(signal, fs):\n",
    "    frames = speechpy.processing.stack_frames(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01, filter=lambda x: np.ones((x,)),zero_padding=True)\n",
    "    power_spectrum = speechpy.processing.power_spectrum(frames, fft_points=1)\n",
    "    logenergy = speechpy.feature.lmfe(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,num_filters=1, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "    mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,num_filters=1, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "    mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "    mfcc_feature_cube = speechpy.feature.extract_derivative_feature(mfcc)\n",
    "    return np.hstack([power_spectrum[:,0],logenergy[:,0],mfcc_cmvn[:,0],mfcc_feature_cube[:,0,1]])\n",
    "\n",
    "def extract_files(folder):\n",
    "    location = folder + '/'\n",
    "    elements = os.listdir(location)\n",
    "    results = []\n",
    "    for i in elements:\n",
    "        try:\n",
    "            fs, signal = wav.read(location+i)\n",
    "            results.append([folder]+extract_features(signal, fs).tolist())\n",
    "        except:\n",
    "            continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folders = [i for i in os.listdir(os.getcwd())if i.find('.md') < 0 and i.find('.txt') < 0 and i.find('ipynb') < 0 and i.find('LICENSE') < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "marvin\n",
      "off\n",
      "happy\n",
      "bed\n",
      "house\n",
      "up\n",
      "six\n",
      "go\n",
      "four\n",
      "nine\n",
      "left\n",
      "no\n",
      "three\n",
      "wow\n",
      "sheila\n",
      "_background_noise_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "on\n",
      "five\n",
      "seven\n",
      "zero\n",
      "stop\n",
      "one\n",
      "down\n",
      "bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/speechpy/processing.py:239: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  variance_normalized[i, :] = mean_subtracted[i, :] / window_variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n",
      "eight\n",
      "dog\n",
      "two\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for i in folders:\n",
    "    print(i)\n",
    "    output += extract_files(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'down',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'four',\n",
       " 'go',\n",
       " 'happy',\n",
       " 'house',\n",
       " 'left',\n",
       " 'marvin',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'right',\n",
       " 'seven',\n",
       " 'sheila',\n",
       " 'six',\n",
       " 'stop',\n",
       " 'three',\n",
       " 'tree',\n",
       " 'two',\n",
       " 'up',\n",
       " 'wow',\n",
       " 'yes',\n",
       " 'zero']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = [i for i in output if len(i) == 397]\n",
    "dataset=np.array(output)\n",
    "np.random.shuffle(dataset)\n",
    "labels = np.unique(dataset[:,0]).tolist()\n",
    "target = LabelEncoder().fit_transform(dataset[:,0])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, size_input, size_output):\n",
    "        self.X = tf.placeholder(tf.float32, (None, size_input))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, size_output))\n",
    "        \n",
    "        w1 = tf.Variable(tf.random_normal([size_input, 784], stddev = np.sqrt(1/size_input)))\n",
    "        b1 = tf.Variable(tf.random_normal([784], stddev = 0))\n",
    "        \n",
    "        w2 = tf.Variable(tf.random_normal([784, 256], stddev = np.sqrt(1/256.0)))\n",
    "        b2 = tf.Variable(tf.random_normal([256], stddev = 0))\n",
    "        \n",
    "        w3 = tf.Variable(tf.random_normal([256, 100], stddev = np.sqrt(1/100.0)))\n",
    "        b3 = tf.Variable(tf.random_normal([100], stddev = 0))\n",
    "        \n",
    "        w4 = tf.Variable(tf.random_normal([100, size_output], stddev = np.sqrt(1/(size_output * 1.0))))\n",
    "        b4 = tf.Variable(tf.random_normal([size_output], stddev = 0))\n",
    "        \n",
    "        hidden1 = tf.nn.relu(tf.matmul(self.X, w1) + b1)\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, w2) + b2)\n",
    "        hidden3 = tf.nn.relu(tf.matmul(hidden2, w3) + b3)\n",
    "        self.logits = tf.matmul(hidden3, w4) + b4\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset[:, 1:].astype('float64')\n",
    "condition = ~np.isnan(dataset).any(axis=1)\n",
    "dataset=dataset[condition]\n",
    "target=target[condition]\n",
    "condition = ~np.isinf(dataset).any(axis=1)\n",
    "dataset=dataset[condition]\n",
    "target=target[condition]\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(MinMaxScaler().fit_transform(dataset), target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100 avg loss:  2.2162935832 avg acc:  0.352056146978 avg time:  0.0022671091687548293\n",
      "epoch:  200 avg loss:  1.87672025195 avg acc:  0.454069368132 avg time:  0.0022755704083285487\n",
      "epoch:  300 avg loss:  1.63823067618 avg acc:  0.526850103022 avg time:  0.002270428688971551\n",
      "epoch:  400 avg loss:  1.44041890725 avg acc:  0.584628262363 avg time:  0.002271171454544906\n",
      "epoch:  500 avg loss:  1.24983836465 avg acc:  0.645368303571 avg time:  0.002266234748966091\n",
      "epoch:  600 avg loss:  1.17506110128 avg acc:  0.666809752747 avg time:  0.0022591955059177273\n",
      "epoch:  700 avg loss:  1.10258197866 avg acc:  0.687993646978 avg time:  0.0022657264719952593\n",
      "epoch:  800 avg loss:  0.944048415665 avg acc:  0.738839285714 avg time:  0.00226986146235204\n",
      "epoch:  900 avg loss:  0.822166120122 avg acc:  0.779361263736 avg time:  0.0022613956378056453\n",
      "epoch:  1000 avg loss:  0.882767829266 avg acc:  0.758434924451 avg time:  0.0022641695462740385\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(train_X.shape[1],len(labels))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "ACCURACY, LOST = [], []\n",
    "for i in range(epoch):\n",
    "    last = time.time()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for k in range(0, (train_X.shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_y = np.zeros((batch_size, len(labels)))\n",
    "        for n in range(batch_size):\n",
    "            batch_y[n, train_Y[k+n]] = 1.0\n",
    "        loss, _ = sess.run([model.cost, model.optimizer], feed_dict = {model.X: train_X[k:k+batch_size,:], model.Y: batch_y})\n",
    "        total_acc += sess.run(model.accuracy, feed_dict = {model.X: train_X[k:k+batch_size,:], model.Y: batch_y})\n",
    "        total_loss += loss\n",
    "    total_loss /= (train_X.shape[0] // batch_size)\n",
    "    total_acc /= (train_X.shape[0] // batch_size)\n",
    "    ACCURACY.append(total_acc)\n",
    "    LOST.append(total_loss)\n",
    "    if (i+1) % 100 == 0:\n",
    "        print('epoch: ', i + 1, 'avg loss: ', total_loss, 'avg acc: ', total_acc, 'avg time: ', (time.time() - last) / (train_X.shape[0] // batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.331731\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bed       0.14      0.11      0.13       298\n",
      "       bird       0.18      0.10      0.13       313\n",
      "        cat       0.21      0.34      0.26       299\n",
      "        dog       0.17      0.19      0.18       302\n",
      "       down       0.24      0.11      0.15       449\n",
      "      eight       0.41      0.35      0.38       415\n",
      "       five       0.25      0.23      0.24       427\n",
      "       four       0.19      0.29      0.23       420\n",
      "         go       0.13      0.15      0.14       456\n",
      "      happy       0.57      0.65      0.61       341\n",
      "      house       0.56      0.46      0.50       300\n",
      "       left       0.32      0.34      0.33       429\n",
      "     marvin       0.47      0.53      0.50       306\n",
      "       nine       0.33      0.22      0.26       434\n",
      "         no       0.24      0.21      0.22       420\n",
      "        off       0.27      0.22      0.24       425\n",
      "         on       0.38      0.16      0.22       466\n",
      "        one       0.18      0.15      0.17       416\n",
      "      right       0.24      0.25      0.24       452\n",
      "      seven       0.48      0.60      0.53       453\n",
      "     sheila       0.38      0.60      0.46       311\n",
      "        six       0.62      0.65      0.64       436\n",
      "       stop       0.50      0.69      0.58       449\n",
      "      three       0.18      0.22      0.20       394\n",
      "       tree       0.38      0.40      0.39       286\n",
      "        two       0.26      0.16      0.20       424\n",
      "         up       0.40      0.52      0.45       415\n",
      "        wow       0.20      0.23      0.21       287\n",
      "        yes       0.49      0.46      0.48       417\n",
      "       zero       0.39      0.41      0.40       411\n",
      "\n",
      "avg / total       0.33      0.33      0.32     11651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_y = np.zeros((test_X.shape[0],len(labels)))\n",
    "for n in range(test_X.shape[0]):\n",
    "    batch_y[n, test_Y[n]] = 1.0\n",
    "acc, logits = sess.run([model.accuracy, tf.cast(tf.argmax(model.logits, 1), tf.int32)], feed_dict = {model.X : test_X, model.Y : batch_y})\n",
    "print('testing accuracy: ' + str(acc))\n",
    "print(metrics.classification_report(test_Y, logits, target_names = labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
