{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QR5KHrc-0eC"
      },
      "source": [
        "# Task-Related Component Analysis\n",
        "\n",
        "Task-related component analysis (TRCA) is a classifier, originally for steady-state visual evoked potentials (SSVEPs) detection.\n",
        "\n",
        "Taken from the [paper](http://ieeexplore.ieee.org/document/7904641/) abstract:\n",
        "> Task-related component analysis (TRCA), which can enhance reproducibility of SSVEPs across multiple trials, was employed to improve the signal-to-noise ratio (SNR) of SSVEP signals by removing background electroencephalographic (EEG) activities. An ensemble method was further developed to integrate TRCA filters corresponding to multiple stimulation frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jn9DFi6-0kr",
        "outputId": "3a1db3f0-5f74-4181-83b3-753b69a9eec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'python-signal-processing'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 198 (delta 111), reused 118 (delta 50), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (198/198), 22.08 MiB | 36.88 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n",
            "/content/python-signal-processing\n"
          ]
        }
      ],
      "source": [
        "#@title \n",
        "!git clone https://github.com/jinglescode/python-signal-processing.git\n",
        "%cd python-signal-processing\n",
        "!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2h9lGUY-1n4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from splearn.cross_decomposition.trca import TRCA # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/cross_decomposition/trca.py\n",
        "from splearn.data.sample_ssvep import SampleSSVEPData # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/data/sample_ssvep.py\n",
        "from splearn.cross_validate.leave_one_out import leave_one_block_evaluation # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/cross_validate.leave_one_out.py\n",
        "from splearn.cross_decomposition.cca import CCA # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/cross_decomposition/cca.py\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noE6FEDCIP_8"
      },
      "source": [
        "## Load data\n",
        "\n",
        "In this tutorial, we load a 40-target steady-state visual evoked potentials (SSVEP) dataset recorded from a single subject. It contains 6 blocks, each block consists of 40 trials, where each trial is a target. The electroencephalogram (EEG) signals has 9 channels and 1250 sampling points.\n",
        "\n",
        "Read more about this dataset: https://www.pnas.org/content/early/2015/10/14/1508080112.abstract."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UisorSY-1qk",
        "outputId": "f025c66f-3ecb-4cc1-ae92-a3c4c3719671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eeg.shape: (6, 40, 9, 1250)\n",
            "labels.shape: (6, 40)\n"
          ]
        }
      ],
      "source": [
        "data = SampleSSVEPData()\n",
        "eeg = data.get_data()\n",
        "labels = data.get_targets()\n",
        "print(\"eeg.shape:\", eeg.shape)\n",
        "print(\"labels.shape:\", labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XcPql_8H2d4"
      },
      "source": [
        "## Leave-One-Block-Out cross-validation\n",
        "\n",
        "We use the Leave-One-Block-Out cross-validation approach to determine TRCA's classification performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUOpOyBU_CcF",
        "outputId": "b9a299b4-d0ab-4045-af23-0025d54be6c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block: 1 | Train acc: 100.00% | Test acc: 97.50%\n",
            "Block: 2 | Train acc: 100.00% | Test acc: 100.00%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-ad1360b3b7d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrca_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTRCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_accuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleave_one_block_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrca_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meeg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mD:\\workspace\\github\\python-signal-processing\\splearn\\cross_validate\\leave_one_out.py\u001b[0m in \u001b[0;36mleave_one_block_evaluation\u001b[1;34m(classifier, X, Y)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mblock_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mtest_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\workspace\\github\\python-signal-processing\\splearn\\cross_validate\\leave_one_out.py\u001b[0m in \u001b[0;36mblock_evaluation\u001b[1;34m(classifier, X, Y, block_i)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\workspace\\github\\python-signal-processing\\splearn\\cross_decomposition\\trca.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m                         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfb_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                         \u001b[1;31m# Follows corrcoef MATLAB function implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                         \u001b[0mr_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfb_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trca_classifier = TRCA(sampling_rate=data.sampling_rate)\n",
        "test_accuracies = leave_one_block_evaluation(classifier=trca_classifier, X=eeg, Y=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ccn3ee-4OZO"
      },
      "source": [
        "### Comparing to CCA\n",
        "Let's also test the classification performance with [CCA](https://colab.research.google.com/github/jinglescode/python-signal-processing/blob/main/tutorials/Canonical%20Correlation%20Analysis.ipynb) and compare the accuracy performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DrOzs9H4HD-",
        "outputId": "a64c333e-f36b-4f5e-9ac4-6b65243803f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block: 1 | Test acc: 100.00%\n",
            "Block: 2 | Test acc: 100.00%\n",
            "Block: 3 | Test acc: 100.00%\n",
            "Block: 4 | Test acc: 100.00%\n",
            "Block: 5 | Test acc: 100.00%\n",
            "Block: 6 | Test acc: 100.00%\n",
            "Mean test accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "cca = CCA(\n",
        "    sampling_rate=data.sampling_rate, \n",
        "    target_frequencies=data.get_stimulus_frequencies(), \n",
        "    signal_size=eeg.shape[3], \n",
        "    num_harmonics=1\n",
        ")\n",
        "\n",
        "test_accuracies = leave_one_block_evaluation(classifier=cca, X=eeg, Y=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VF6_inPQIYH"
      },
      "source": [
        "Comparing the `mean test accuracy`, we can't see the difference in the classification performance between TRCA and CCA. We will use another dataset below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggjguM6YDOke"
      },
      "source": [
        "## Using `.fit` and `.predict`\n",
        "\n",
        "In this example, we select the first 2 blocks for training and the remaining 4 blocks for testing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsLQSLggDOrY",
        "outputId": "be4f5c33-048d-4dd7-a8ce-cccc25ffed64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (80, 9, 1250) (80,)\n",
            "Block: 3 | accuracy: 100.00%\n",
            "Block: 4 | accuracy: 100.00%\n",
            "Block: 5 | accuracy: 97.50%\n",
            "Block: 6 | accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "trca_classifier = TRCA(sampling_rate=data.sampling_rate)\n",
        "\n",
        "x_train = eeg[0:2]\n",
        "y_train = labels[0:2]\n",
        "\n",
        "blocks, targets, channels, samples = x_train.shape\n",
        "x_train = x_train.reshape((blocks-1*targets, channels, samples))\n",
        "y_train = y_train.reshape((blocks-1*targets))\n",
        "\n",
        "print(\"Train shape:\", x_train.shape, y_train.shape)\n",
        "trca_classifier.fit(x_train, y_train)\n",
        "\n",
        "for block_i in range(2, 6):\n",
        "\n",
        "    test_x = eeg[block_i]\n",
        "    test_y = labels[block_i]\n",
        "\n",
        "    # Shuffle the test set\n",
        "    arrangement = np.arange(40)\n",
        "    np.random.shuffle(arrangement)\n",
        "    test_x = test_x[arrangement, :,:]\n",
        "    test_y = test_y[arrangement]\n",
        "\n",
        "    # Preduct\n",
        "    pred = trca_classifier.predict(test_x)\n",
        "    acc = accuracy_score(test_y, pred)\n",
        "\n",
        "    print(f'Block: {block_i+1} | accuracy: {acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ItEaQy3ewU"
      },
      "source": [
        "## Another dataset, HS-SSVEP\n",
        "\n",
        "As we can't see the difference in classification performance with the previous data, in this example we will evaluate with a single subject data taken from the [Tsinghua SSVEP benchmark dataset](https://ieeexplore.ieee.org/document/7740878).\n",
        "\n",
        "In the following code blocks, we will download and prepare the data and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z1jdUGw3e4g",
        "outputId": "52a0c191-c343-43fd-a8ad-a9b84d6a4892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-08-18 13:12:13--  ftp://anonymous@sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat\n",
            "           => ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/.listing’\n",
            "Resolving sccn.ucsd.edu (sccn.ucsd.edu)... 169.228.38.2\n",
            "Connecting to sccn.ucsd.edu (sccn.ucsd.edu)|169.228.38.2|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /pub/ssvep_benchmark_dataset ... done.\n",
            "==> PASV ... done.    ==> LIST ... done.\n",
            "\n",
            "sccn.ucsd.edu/pub/s     [ <=>                ]   2.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-18 13:12:14 (261 MB/s) - ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/.listing’ saved [2850]\n",
            "\n",
            "Removed ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/.listing’.\n",
            "--2021-08-18 13:12:14--  ftp://anonymous@sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat\n",
            "           => ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR S33.mat ... done.\n",
            "Length: 106223727 (101M)\n",
            "\n",
            "sccn.ucsd.edu/pub/s 100%[===================>] 101.30M  34.5MB/s    in 2.9s    \n",
            "\n",
            "2021-08-18 13:12:17 (34.5 MB/s) - ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat’ saved [106223727]\n",
            "\n",
            "FINISHED --2021-08-18 13:12:17--\n",
            "Total wall clock time: 4.1s\n",
            "Downloaded: 1 files, 101M in 2.9s (34.5 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!wget -r --no-parent ftp://anonymous@sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkUyEd_l3lV6",
        "outputId": "a2c1ccaa-358c-46d3-fffe-7d5c1cb0a011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (6, 40, 9, 250)\n",
            "Label shape: (200,) (40,)\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "# select channels\n",
        "ch_names = ['FP1','FPZ','FP2','AF3','AF4','F7','F5','F3','F1','FZ','F2','F4','F6','F8','FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8','T7','C5','C3','C1','Cz','C2','C4','C6','T8','M1','TP7','CP5','CP3','CP1','CPZ','CP2','CP4','CP6','TP8','M2','P7','P5','P3','P1','PZ','P2','P4','P6','P8','PO7','PO5','PO3','POz','PO4','PO6','PO8','CB1','O1','Oz','O2','CB2']\n",
        "ch_index = [47,53,54,55,56,57,60,61,62]\n",
        "\n",
        "sampling_rate = 250\n",
        "\n",
        "folder = 'sccn.ucsd.edu/pub/ssvep_benchmark_dataset'\n",
        "data = loadmat(f\"{folder}/S33.mat\")\n",
        "eeg = data['data']\n",
        "eeg = eeg.transpose((3, 2, 0, 1))\n",
        "eeg = eeg[:,  :, ch_index, 250:500]\n",
        "print(\"Data shape:\", eeg.shape)\n",
        "\n",
        "blocks, targets, channels, samples = eeg.shape\n",
        "y_train = np.tile(np.arange(0, targets), (1, blocks-1)).squeeze()\n",
        "y_test = np.arange(0, targets)\n",
        "print(\"Label shape:\", y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPTZLMIGTU_E"
      },
      "source": [
        "## Classification with TRCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hchO2WOS7DDh",
        "outputId": "98d7404f-db78-45b6-c83d-ae81f50c9bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block: 1 | Train acc: 100.00% | Test acc: 70.00%\n",
            "Block: 2 | Train acc: 100.00% | Test acc: 47.50%\n",
            "Block: 3 | Train acc: 100.00% | Test acc: 67.50%\n",
            "Block: 4 | Train acc: 100.00% | Test acc: 47.50%\n",
            "Block: 5 | Train acc: 100.00% | Test acc: 70.00%\n",
            "Block: 6 | Train acc: 100.00% | Test acc: 62.50%\n",
            "Mean test accuracy: 60.8%\n"
          ]
        }
      ],
      "source": [
        "trca_classifier = TRCA(sampling_rate=sampling_rate)\n",
        "test_accuracies = leave_one_block_evaluation(classifier=trca_classifier, X=eeg, Y=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhHEECitTaMM"
      },
      "source": [
        "### Comparing to CCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBJCxXaz6jpa",
        "outputId": "c5d097a1-5a26-47a6-fad7-3d2da7943cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block: 1 | Train acc: 20.50% | Test acc: 35.00%\n",
            "Block: 2 | Train acc: 26.00% | Test acc: 7.50%\n",
            "Block: 3 | Train acc: 22.00% | Test acc: 27.50%\n",
            "Block: 4 | Train acc: 23.50% | Test acc: 20.00%\n",
            "Block: 5 | Train acc: 23.50% | Test acc: 20.00%\n",
            "Block: 6 | Train acc: 22.00% | Test acc: 27.50%\n",
            "Mean test accuracy: 22.900000000000002%\n"
          ]
        }
      ],
      "source": [
        "stimulus_frequencies = np.array([8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,8.2,9.2,10.2,11.2,12.2,13.2,14.2,15.2,8.4,9.4,10.4,11.4,12.4,13.4,14.4,15.4,8.6,9.6,10.6,11.6,12.6,13.6,14.6,15.6,8.8,9.8,10.8,11.8,12.8,13.8,14.8,15.8])\n",
        "\n",
        "cca = CCA(\n",
        "    sampling_rate=sampling_rate, \n",
        "    target_frequencies=stimulus_frequencies,\n",
        "    signal_size=eeg.shape[3], \n",
        "    num_harmonics=2\n",
        ")\n",
        "\n",
        "test_accuracies = leave_one_block_evaluation(classifier=cca, X=eeg, Y=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8TednsqTibG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZVQFEFUTibN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl-TfCrkTibO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtagjqWhTibO"
      },
      "outputs": [],
      "source": [
        "\"\"\"TRCA utils.\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "from scipy.signal import filtfilt, cheb1ord, cheby1\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "def round_half_up(num, decimals=0):\n",
        "    \"\"\"Round half up round the last decimal of the number.\n",
        "    The rules are:\n",
        "    from 0 to 4 rounds down\n",
        "    from 5 to 9 rounds up\n",
        "    Parameters\n",
        "    ----------\n",
        "    num : float\n",
        "        Number to round\n",
        "    decimals : number of decimals\n",
        "    Returns\n",
        "    -------\n",
        "    num rounded\n",
        "    \"\"\"\n",
        "    multiplier = 10 ** decimals\n",
        "    return int(np.floor(num * multiplier + 0.5) / multiplier)\n",
        "\n",
        "\n",
        "def normfit(data, ci=0.95):\n",
        "    \"\"\"Compute the mean, std and confidence interval for them.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : array, shape=()\n",
        "        Input data.\n",
        "    ci : float\n",
        "        Confidence interval (default=0.95).\n",
        "    Returns\n",
        "    -------\n",
        "    m : float\n",
        "        Mean.\n",
        "    sigma : float\n",
        "        Standard deviation\n",
        "    [m - h, m + h] : list\n",
        "        Confidence interval of the mean.\n",
        "    [sigmaCI_lower, sigmaCI_upper] : list\n",
        "        Confidence interval of the std.\n",
        "    \"\"\"\n",
        "    arr = 1.0 * np.array(data)\n",
        "    num = len(arr)\n",
        "    avg, std_err = np.mean(arr), stats.sem(arr)\n",
        "    h_int = std_err * stats.t.ppf((1 + ci) / 2., num - 1)\n",
        "    var = np.var(data, ddof=1)\n",
        "    var_ci_upper = var * (num - 1) / stats.chi2.ppf((1 - ci) / 2, num - 1)\n",
        "    var_ci_lower = var * (num - 1) / stats.chi2.ppf(1 - (1 - ci) / 2, num - 1)\n",
        "    sigma = np.sqrt(var)\n",
        "    sigma_ci_lower = np.sqrt(var_ci_lower)\n",
        "    sigma_ci_upper = np.sqrt(var_ci_upper)\n",
        "\n",
        "    return avg, sigma, [avg - h_int, avg +\n",
        "                        h_int], [sigma_ci_lower, sigma_ci_upper]\n",
        "\n",
        "\n",
        "def itr(n, p, t):\n",
        "    \"\"\"Compute information transfer rate (ITR).\n",
        "    Definition in [1]_.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n : int\n",
        "        Number of targets.\n",
        "    p : float\n",
        "        Target identification accuracy (0 <= p <= 1).\n",
        "    t : float\n",
        "        Average time for a selection (s).\n",
        "    Returns\n",
        "    -------\n",
        "    itr : float\n",
        "        Information transfer rate [bits/min]\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] M. Cheng, X. Gao, S. Gao, and D. Xu,\n",
        "        \"Design and Implementation of a Brain-Computer Interface With High\n",
        "        Transfer Rates\", IEEE Trans. Biomed. Eng. 49, 1181-1186, 2002.\n",
        "    \"\"\"\n",
        "    itr = 0\n",
        "\n",
        "    if (p < 0 or 1 < p):\n",
        "        raise ValueError('Accuracy need to be between 0 and 1.')\n",
        "    elif (p < 1 / n):\n",
        "        itr = 0\n",
        "        raise ValueError('ITR might be incorrect because accuracy < chance')\n",
        "    elif (p == 1):\n",
        "        itr = np.log2(n) * 60 / t\n",
        "    else:\n",
        "        itr = (np.log2(n) + p * np.log2(p) + (1 - p) *\n",
        "               np.log2((1 - p) / (n - 1))) * 60 / t\n",
        "\n",
        "    return itr\n",
        "\n",
        "\n",
        "def bandpass(eeg, sfreq, Wp, Ws):\n",
        "    \"\"\"Filter bank design for decomposing EEG data into sub-band components.\n",
        "    Parameters\n",
        "    ----------\n",
        "    eeg : np.array, shape=(n_samples, n_chans[, n_trials])\n",
        "        Training data.\n",
        "    sfreq : int\n",
        "        Sampling frequency of the data.\n",
        "    Wp : 2-tuple\n",
        "        Passband for Chebyshev filter.\n",
        "    Ws : 2-tuple\n",
        "        Stopband for Chebyshev filter.\n",
        "    Returns\n",
        "    -------\n",
        "    y: np.array, shape=(n_trials, n_chans, n_samples)\n",
        "        Sub-band components decomposed by a filter bank.\n",
        "    See Also\n",
        "    --------\n",
        "    scipy.signal.cheb1ord :\n",
        "        Chebyshev type I filter order selection.\n",
        "    \"\"\"\n",
        "    # Chebyshev type I filter order selection.\n",
        "    N, Wn = cheb1ord(Wp, Ws, 3, 40, fs=sfreq)\n",
        "\n",
        "    # Chebyshev type I filter design\n",
        "    B, A = cheby1(N, 0.5, Wn, btype=\"bandpass\", fs=sfreq)\n",
        "\n",
        "    # the arguments 'axis=0, padtype='odd', padlen=3*(max(len(B),len(A))-1)'\n",
        "    # correspond to Matlab filtfilt : https://dsp.stackexchange.com/a/47945\n",
        "    y = filtfilt(B, A, eeg, axis=0, padtype='odd',\n",
        "                 padlen=3 * (max(len(B), len(A)) - 1))\n",
        "    return y\n",
        "\n",
        "\n",
        "def schaefer_strimmer_cov(X):\n",
        "    r\"\"\"Schaefer-Strimmer covariance estimator.\n",
        "    Shrinkage estimator described in [1]_:\n",
        "    .. math:: \\hat{\\Sigma} = (1 - \\gamma)\\Sigma_{scm} + \\gamma T\n",
        "    where :math:`T` is the diagonal target matrix:\n",
        "    .. math:: T_{i,j} = \\{ \\Sigma_{scm}^{ii} \\text{if} i = j,\n",
        "         0 \\text{otherwise} \\}\n",
        "    Note that the optimal :math:`\\gamma` is estimated by the authors' method.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: array, shape=(n_chans, n_samples)\n",
        "        Signal matrix.\n",
        "    Returns\n",
        "    -------\n",
        "    cov: array, shape=(n_chans, n_chans)\n",
        "        Schaefer-Strimmer shrinkage covariance matrix.\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Schafer, J., and K. Strimmer. 2005. A shrinkage approach to\n",
        "       large-scale covariance estimation and implications for functional\n",
        "       genomics. Statist. Appl. Genet. Mol. Biol. 4:32.\n",
        "    \"\"\"\n",
        "    ns = X.shape[1]\n",
        "    C_scm = np.cov(X, ddof=0)\n",
        "    X_c = X - np.tile(X.mean(axis=1), [ns, 1]).T\n",
        "\n",
        "    # Compute optimal gamma, the weigthing between SCM and srinkage estimator\n",
        "    R = ns / (ns - 1.0) * np.corrcoef(X)\n",
        "    var_R = (X_c ** 2).dot((X_c ** 2).T) - 2 * C_scm * X_c.dot(X_c.T)\n",
        "    var_R += ns * C_scm ** 2\n",
        "\n",
        "    var_R = ns / ((ns - 1) ** 3 * np.outer(X.var(1), X.var(1))) * var_R\n",
        "    R -= np.diag(np.diag(R))\n",
        "    var_R -= np.diag(np.diag(var_R))\n",
        "    gamma = max(0, min(1, var_R.sum() / (R ** 2).sum()))\n",
        "\n",
        "    cov = (1. - gamma) * (ns / (ns - 1.)) * C_scm\n",
        "    cov += gamma * (ns / (ns - 1.)) * np.diag(np.diag(C_scm))\n",
        "\n",
        "    return cov\n",
        "\n",
        "\n",
        "def _check_data(X):\n",
        "    \"\"\"Check data is numpy array and has the proper dimensions.\"\"\"\n",
        "    if not isinstance(X, (np.ndarray, list)):\n",
        "        raise AttributeError('data should be a list or a numpy array')\n",
        "\n",
        "    dtype = np.complex128 if np.any(np.iscomplex(X)) else np.float64\n",
        "    X = np.asanyarray(X, dtype=dtype)\n",
        "    if X.ndim > 3:\n",
        "        raise ValueError('Data must be 3D at most')\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def theshapeof(X):\n",
        "    \"\"\"Return the shape of X.\"\"\"\n",
        "    X = _check_data(X)\n",
        "    # if not isinstance(X, np.ndarray):\n",
        "    #     raise AttributeError('X must be a numpy array')\n",
        "\n",
        "    if X.ndim == 3:\n",
        "        return X.shape[0], X.shape[1], X.shape[2]\n",
        "    elif X.ndim == 2:\n",
        "        return X.shape[0], X.shape[1], 1\n",
        "    elif X.ndim == 1:\n",
        "        return X.shape[0], 1, 1\n",
        "    else:\n",
        "        raise ValueError(\"Array contains more than 3 dimensions\")\n",
        "\n",
        "        \n",
        "###################\n",
        "\n",
        "\n",
        "\"\"\"Task-Related Component Analysis.\"\"\"\n",
        "# Authors: Giuseppe Ferraro <giuseppe.ferraro@isae-supaero.fr>\n",
        "#          Ludovic Darmet <ludovic.darmet@isae-supaero.fr>\n",
        "import numpy as np\n",
        "import scipy.linalg as linalg\n",
        "from pyriemann.utils.mean import mean_covariance\n",
        "from pyriemann.estimation import Covariances\n",
        "\n",
        "\n",
        "class TRCA:\n",
        "    \"\"\"Task-Related Component Analysis (TRCA).\n",
        "    Parameters\n",
        "    ----------\n",
        "    sfreq : float\n",
        "        Sampling rate.\n",
        "    filterbank : list[[2-tuple, 2-tuple]]\n",
        "        Filterbank frequencies. Each list element is itself a list of passband\n",
        "        `Wp` and stopband `Ws` edges frequencies `[Wp, Ws]`. For example, this\n",
        "        creates 3 bands, starting at 6, 14, and 22 hz respectively::\n",
        "            [[(6, 90), (4, 100)],\n",
        "             [(14, 90), (10, 100)],\n",
        "             [(22, 90), (16, 100)]]\n",
        "        See :func:`scipy.signal.cheb1ord()` for more information on how to\n",
        "        specify the `Wp` and `Ws`.\n",
        "    ensemble : bool\n",
        "        If True, perform the ensemble TRCA analysis (default=False).\n",
        "    method : str in {'original'| 'riemann'}\n",
        "        Use original implementation from [1]_ or a variation that uses\n",
        "        regularization and the geodesic mean [2]_.\n",
        "    regularization : str in {'schaefer' | 'lwf' | 'oas' | 'scm'}\n",
        "        Regularization estimator used for covariance estimation with the\n",
        "        `riemann` method. Consider 'schaefer', 'lwf', 'oas'. 'scm' does not add\n",
        "        regularization and is almost equivalent to the original implementation.\n",
        "    Attributes\n",
        "    ----------\n",
        "    traindata : array, shape=(n_bands, n_chans, n_trials)\n",
        "        Reference (training) data decomposed into sub-band components by the\n",
        "        filter bank analysis.\n",
        "    y_train : array, shape=(n_trials)\n",
        "        Labels associated with the train data.\n",
        "    coef_ : array, shape=(n_chans, n_chans)\n",
        "        Weight coefficients for electrodes which can be used as a spatial\n",
        "        filter.\n",
        "    classes : list\n",
        "        Classes.\n",
        "    n_bands : int\n",
        "        Number of sub-bands.\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
        "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
        "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
        "       65(1):104-112, 2018.\n",
        "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
        "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
        "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
        "       472-476). IEEE.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sfreq, filterbank, ensemble=False, method='original',\n",
        "                 estimator='scm'):\n",
        "        self.sfreq = sfreq\n",
        "        self.ensemble = ensemble\n",
        "        self.filterbank = filterbank\n",
        "        self.n_bands = len(self.filterbank)\n",
        "        self.coef_ = None\n",
        "        self.method = method\n",
        "        if estimator == 'schaefer':\n",
        "            self.estimator = schaefer_strimmer_cov\n",
        "        else:\n",
        "            self.estimator = estimator\n",
        "            \n",
        "        self.can_train = True\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Training stage of the TRCA-based SSVEP detection.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array, shape=(n_samples, n_chans[, n_trials])\n",
        "            Training EEG data.\n",
        "        y : array, shape=(trials,)\n",
        "            True label corresponding to each trial of the data array.\n",
        "        \"\"\"\n",
        "        \n",
        "        X = np.transpose(X, (2,1,0))\n",
        "        \n",
        "        n_samples, n_chans, _ = theshapeof(X)\n",
        "        classes = np.unique(y)\n",
        "\n",
        "        trains = np.zeros((len(classes), self.n_bands, n_samples, n_chans))\n",
        "\n",
        "        W = np.zeros((self.n_bands, len(classes), n_chans))\n",
        "\n",
        "        for class_i in classes:\n",
        "            # Select data with a specific label\n",
        "            eeg_tmp = X[..., y == class_i]\n",
        "            for fb_i in range(self.n_bands):\n",
        "                # Filter the signal with fb_i\n",
        "                eeg_tmp = bandpass(eeg_tmp, self.sfreq,\n",
        "                                   Wp=self.filterbank[fb_i][0],\n",
        "                                   Ws=self.filterbank[fb_i][1])\n",
        "                if (eeg_tmp.ndim == 3):\n",
        "                    # Compute mean of the signal across trials\n",
        "                    trains[class_i, fb_i] = np.mean(eeg_tmp, -1)\n",
        "                else:\n",
        "                    trains[class_i, fb_i] = eeg_tmp\n",
        "                # Find the spatial filter for the corresponding filtered signal\n",
        "                # and label\n",
        "                if self.method == 'original':\n",
        "                    w_best = trca(eeg_tmp)\n",
        "                elif self.method == 'riemann':\n",
        "                    w_best = trca_regul(eeg_tmp, self.estimator)\n",
        "                else:\n",
        "                    raise ValueError('Invalid `method` option.')\n",
        "\n",
        "                W[fb_i, class_i, :] = w_best  # Store the spatial filter\n",
        "\n",
        "        self.trains = trains\n",
        "        self.coef_ = W\n",
        "        self.classes = classes\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Test phase of the TRCA-based SSVEP detection.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: array, shape=(n_samples, n_chans[, n_trials])\n",
        "            Test data.\n",
        "        model: dict\n",
        "            Fitted model to be used in testing phase.\n",
        "        Returns\n",
        "        -------\n",
        "        pred: np.array, shape (trials)\n",
        "            The target estimated by the method.\n",
        "        \"\"\"\n",
        "        \n",
        "        X = np.transpose(X, (2,1,0))\n",
        "        \n",
        "        if self.coef_ is None:\n",
        "            raise RuntimeError('TRCA is not fitted')\n",
        "\n",
        "        # Alpha coefficients for the fusion of filterbank analysis\n",
        "        fb_coefs = [(x + 1)**(-1.25) + 0.25 for x in range(self.n_bands)]\n",
        "        _, _, n_trials = theshapeof(X)\n",
        "\n",
        "        r = np.zeros((self.n_bands, len(self.classes)))\n",
        "        pred = np.zeros((n_trials), 'int')  # To store predictions\n",
        "\n",
        "        for trial in range(n_trials):\n",
        "            test_tmp = X[..., trial]  # pick a trial to be analysed\n",
        "            for fb_i in range(self.n_bands):\n",
        "\n",
        "                # filterbank on testdata\n",
        "                testdata = bandpass(test_tmp, self.sfreq,\n",
        "                                    Wp=self.filterbank[fb_i][0],\n",
        "                                    Ws=self.filterbank[fb_i][1])\n",
        "\n",
        "                for class_i in self.classes:\n",
        "                    # Retrieve reference signal for class i\n",
        "                    # (shape: n_chans, n_samples)\n",
        "                    traindata = np.squeeze(self.trains[class_i, fb_i])\n",
        "                    if self.ensemble:\n",
        "                        # shape = (n_chans, n_classes)\n",
        "                        w = np.squeeze(self.coef_[fb_i]).T\n",
        "                    else:\n",
        "                        # shape = (n_chans)\n",
        "                        w = np.squeeze(self.coef_[fb_i, class_i])\n",
        "\n",
        "                    # Compute 2D correlation of spatially filtered test data\n",
        "                    # with ref\n",
        "                    r_tmp = np.corrcoef((testdata @ w).flatten(),\n",
        "                                        (traindata @ w).flatten())\n",
        "                    r[fb_i, class_i] = r_tmp[0, 1]\n",
        "\n",
        "            rho = np.dot(fb_coefs, r)  # fusion for the filterbank analysis\n",
        "\n",
        "            tau = np.argmax(rho)  # retrieving index of the max\n",
        "            pred[trial] = int(tau)\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "def trca(X):\n",
        "    \"\"\"Task-related component analysis.\n",
        "    This function implements the method described in [1]_.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
        "        Training data.\n",
        "    Returns\n",
        "    -------\n",
        "    W : array, shape=(n_chans,)\n",
        "        Weight coefficients for electrodes which can be used as a spatial\n",
        "        filter.\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
        "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
        "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
        "       65(1):104-112, 2018.\n",
        "    \"\"\"\n",
        "    n_samples, n_chans, n_trials = theshapeof(X)\n",
        "\n",
        "    # 1. Compute empirical covariance of all data (to be bounded)\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Concatenate all the trials to have all the data as a sequence\n",
        "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
        "    for trial in range(n_trials):\n",
        "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
        "\n",
        "    # Mean centering\n",
        "    UX -= np.mean(UX, 1)[:, None]\n",
        "\n",
        "    # Covariance\n",
        "    Q = UX @ UX.T\n",
        "\n",
        "    # 2. Compute average empirical covariance between all pairs of trials\n",
        "    # -------------------------------------------------------------------------\n",
        "    S = np.zeros((n_chans, n_chans))\n",
        "    for trial_i in range(n_trials - 1):\n",
        "        x1 = np.squeeze(X[..., trial_i])\n",
        "\n",
        "        # Mean centering for the selected trial\n",
        "        x1 -= np.mean(x1, 0)\n",
        "\n",
        "        # Select a second trial that is different\n",
        "        for trial_j in range(trial_i + 1, n_trials):\n",
        "            x2 = np.squeeze(X[..., trial_j])\n",
        "\n",
        "            # Mean centering for the selected trial\n",
        "            x2 -= np.mean(x2, 0)\n",
        "\n",
        "            # Compute empirical covariance between the two selected trials and\n",
        "            # sum it\n",
        "            S = S + x1.T @ x2 + x2.T @ x1\n",
        "\n",
        "    # 3. Compute eigenvalues and vectors\n",
        "    # -------------------------------------------------------------------------\n",
        "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
        "\n",
        "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
        "    W_best = W[:, np.argmax(lambdas)]\n",
        "\n",
        "    return W_best\n",
        "\n",
        "\n",
        "def trca_regul(X, method):\n",
        "    \"\"\"Task-related component analysis.\n",
        "    This function implements a variation of the method described in [1]_. It is\n",
        "    inspired by a riemannian geometry approach to CSP [2]_. It adds\n",
        "    regularization to the covariance matrices and uses the riemannian mean for\n",
        "    the inter-trial covariance matrix `S`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
        "        Training data.\n",
        "    Returns\n",
        "    -------\n",
        "    W : array, shape=(n_chans,)\n",
        "        Weight coefficients for electrodes which can be used as a spatial\n",
        "        filter.\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
        "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
        "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
        "       65(1):104-112, 2018.\n",
        "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
        "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
        "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
        "       472-476). IEEE.\n",
        "    \"\"\"\n",
        "    n_samples, n_chans, n_trials = theshapeof(X)\n",
        "\n",
        "    # 1. Compute empirical covariance of all data (to be bounded)\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Concatenate all the trials to have all the data as a sequence\n",
        "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
        "    for trial in range(n_trials):\n",
        "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
        "\n",
        "    # Mean centering\n",
        "    UX -= np.mean(UX, 1)[:, None]\n",
        "\n",
        "    # Compute empirical variance of all data (to be bounded)\n",
        "    cov = Covariances(estimator=method).fit_transform(UX[np.newaxis, ...])\n",
        "    Q = np.squeeze(cov)\n",
        "\n",
        "    # 2. Compute average empirical covariance between all pairs of trials\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Intertrial correlation computation\n",
        "    data = np.concatenate((X, X), axis=1)\n",
        "\n",
        "    # Swapaxes to fit pyriemann Covariances\n",
        "    data = np.swapaxes(data, 0, 2)\n",
        "    cov = Covariances(estimator=method).fit_transform(data)\n",
        "\n",
        "    # Keep only inter-trial\n",
        "    S = cov[:, :n_chans, n_chans:] + cov[:, n_chans:, :n_chans]\n",
        "\n",
        "    # If the number of samples is too big, we compute an approximate of\n",
        "    # riemannian mean to speed up the computation\n",
        "    if n_trials < 30:\n",
        "        S = mean_covariance(S, metric='riemann')\n",
        "    else:\n",
        "        S = mean_covariance(S, metric='logeuclid')\n",
        "\n",
        "    # 3. Compute eigenvalues and vectors\n",
        "    # -------------------------------------------------------------------------\n",
        "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
        "\n",
        "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
        "    W_best = W[:, np.argmax(lambdas)]\n",
        "\n",
        "    return W_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3X97pkQTibW",
        "outputId": "a92f82ae-191c-4761-884e-2bc615eed5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block: 1 | Train acc: 100.00% | Test acc: 97.50%\n",
            "Block: 2 | Train acc: 100.00% | Test acc: 100.00%\n",
            "Block: 3 | Train acc: 100.00% | Test acc: 100.00%\n",
            "Block: 4 | Train acc: 100.00% | Test acc: 100.00%\n",
            "Block: 5 | Train acc: 100.00% | Test acc: 97.50%\n",
            "Block: 6 | Train acc: 100.00% | Test acc: 100.00%\n",
            "Mean test accuracy: 99.2%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.975, 1.0, 1.0, 1.0, 0.975, 1.0]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sfreq = data.sampling_rate\n",
        "filterbank = [[(6, 90), (4, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n",
        "              [(14, 90), (10, 100)],\n",
        "              [(22, 90), (16, 100)],\n",
        "              [(30, 90), (24, 100)],\n",
        "              [(38, 90), (32, 100)],\n",
        "              [(46, 90), (40, 100)],\n",
        "              [(54, 90), (48, 100)]]\n",
        "\n",
        "trca_classifier = TRCA(sfreq, filterbank, True)\n",
        "test_accuracies = leave_one_block_evaluation(classifier=trca_classifier, X=eeg, Y=labels)\n",
        "test_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LJhGF0_Tibb",
        "outputId": "00720cd4-ccac-4f22-fc3b-a3c92fdcdd49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.4129396046028053"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eeg[0,0,0,0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Task-Related Component Analysis",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}